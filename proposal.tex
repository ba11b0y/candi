\documentclass{article}
\usepackage{verbatim}
\usepackage{cite}

\begin{comment}
    An one-page project proposal is due on 10/01.
    It should contain the project title, problem definition, existing methods and their limitations, the proposed method, the targeted output and timeline.
\end{comment}

\title{candi: Collusion ANomaly Detection using Interpretability}
\author{Harith Laxman and Rahul Tiwari}
\date{September 30 2025}

\begin{document}
\maketitle

% This proposal is about investigating mechanistic anomaly detection (MAD) or eveninterpretability in general as a method to identify
% and mitigate secret collusion in large language models. Recent work shows that colluding models can embed covert communication strategies
% in generated outputs that are invisible to standard evaluations, creating serious risks for alignment and security. By analysing internal
% activations/attention patterns to detect deviations from expected computation pathways, we aim to track whether hidden collusion circuits
% emerge and persist during inference. 
% Success in this direction could provide a principled path toward detecting and preventing collusion that bypasses traditional defences.


\section{Problem}

With AI agents gaining popularity, there is a growing concern about the ability of AI agents to circumvent security oversight.
Recent work \cite{motwani2024secret} shows that colluding models can embed covert communication strategies undectable to overseers.
The work also ascertained that as models grow larger, the capabilities of the colluding models to perform secret collusion also grow.
While these findings establish the problem, the work does not provide a strong methodology to detect secret collusion.
Existing methods to detect secret collusion such as monitoring, paraphrasing, and parameter optimization, are not effective.
While mechanistic anomaly detection (MAD) is a promising approach to detect secret collusion, it has mostly been used to detect backdoors \cite{jenner2024gentle}.

\section{Proposed Method}

Mallen et al. \cite{mallen2023eliciting} in their work have shown that patterns in neural network's activations can track the true
behavior of the model even when the model's output is hard to verify or in our case colluding.
We propose to use mechanistic anomaly detection (MAD) and interpretability in general to detect secret collusion
and build a comprehensive evaluation framework to detect secret collusion in multi-agent settings.

\section{Timeline}

\begin{itemize}
    \item Week 1: Reproduce the results of the paper \cite{motwani2024secret} in a multi-agent setting with open-source models and collect conversation transcripts of the colluding models.
    \item Week 2: Set up instrumentation to collect internal activations and attention patterns in both colluding and regular scenarios.
    \item Week 3: Apply mechanistic anomaly detection (clustering, PCA, probing) to find distinguishing features of collusion.
    \item Week 4: Evaluate the proposed method and setup a comprehensive evaluation framework.
    \item Week 5: Draft all findings in a report.
\end{itemize}

\bibliography{ref.bib}
\bibliographystyle{plain}
\end{document}
