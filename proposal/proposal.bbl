\begin{thebibliography}{1}

\bibitem{ai4privacy_2024}
Ai4Privacy.
\newblock pii-masking-300k (revision 86db63b), 2024.

\bibitem{cywinski2025towards}
Bartosz Cywi{\'n}ski, Emil Ryd, Senthooran Rajamanoharan, and Neel Nanda.
\newblock Towards eliciting latent knowledge from llms with mechanistic interpretability.
\newblock {\em arXiv preprint arXiv:2505.14352}, 2025.

\bibitem{gemma_2b_it}
Gemma 2b instruction tuned model on hugging face, 2025.

\bibitem{hu2022lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, Weizhu Chen, et~al.
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em ICLR}, 1(2):3, 2022.

\bibitem{llm_finetuning_mit}
Llm finetuning on mit deep learning course, 2025.

\bibitem{marks2025auditing}
Samuel Marks, Johannes Treutlein, Trenton Bricken, Jack Lindsey, Jonathan Marcus, Siddharth Mishra-Sharma, Daniel Ziegler, Emmanuel Ameisen, Joshua Batson, Tim Belonax, et~al.
\newblock Auditing language models for hidden objectives.
\newblock {\em arXiv preprint arXiv:2503.10965}, 2025.

\bibitem{peft_huggingface}
Peft on hugging face, 2025.

\end{thebibliography}
